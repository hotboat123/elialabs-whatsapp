# üîå Integraci√≥n MCP (Model Context Protocol)

## ‚úÖ Estado Actual

El bot ahora tiene **compatibilidad completa con MCP servers** gracias a Groq, que soporta el protocolo compatible con OpenAI function calling.

## üéØ ¬øQu√© es MCP?

**Model Context Protocol (MCP)** es un protocolo desarrollado por Anthropic que permite que los modelos de IA se conecten con servicios externos y herramientas en tiempo real. Esto permite:

- Conectarse a bases de datos
- Interactuar con APIs externas
- Usar herramientas de navegaci√≥n web
- Integrar con servicios como GitHub, Stripe, etc.

## üöÄ C√≥mo Funciona con Groq

Groq tiene soporte nativo para **function calling** compatible con OpenAI, lo que significa que:

1. ‚úÖ El modelo puede decidir cu√°ndo usar herramientas
2. ‚úÖ Las herramientas se llaman autom√°ticamente cuando el modelo las necesita
3. ‚úÖ El resultado de la herramienta se incluye en la respuesta final

## üìÅ Archivos Creados

### `app/bot/mcp_handler.py`
Maneja las conexiones a servidores MCP y la ejecuci√≥n de herramientas.

**Caracter√≠sticas:**
- Gesti√≥n de m√∫ltiples servidores MCP
- Registro de herramientas disponibles
- Ejecuci√≥n de llamadas a herramientas
- Formato compatible con OpenAI function calling

### `app/bot/ai_handler.py` (actualizado)
Ahora incluye:
- Soporte para MCP handlers
- Detecci√≥n autom√°tica de herramientas disponibles
- Manejo de tool calling del modelo
- Respuestas con contexto de herramientas

### `mcp_servers/openai_server.py` (nuevo)
- Servidor FastAPI que expone el tool `openai_chat`
- Usa el SDK oficial de OpenAI para generar la respuesta final
- Construye contexto directamente desde tu base de datos PostgreSQL (usa `DATABASE_URL`)
- Incluye autenticaci√≥n por token y configuraci√≥n v√≠a variables de entorno

## üîß C√≥mo Agregar Servidores MCP

### Paso 1: Configurar un Servidor MCP

Edita `app/bot/ai_handler.py` y agrega tu servidor en el m√©todo `_initialize_mcp_servers()`:

```python
def _initialize_mcp_servers(self):
    """Initialize MCP servers from configuration"""
    
    # Ejemplo: Servidor MCP para base de datos
    self.mcp_handler.add_mcp_server("database", {
        "url": "https://mcp-server.example.com",
        "api_key": None,
        "tools": [
            {
                "name": "query_database",
                "description": "Query the database for customer information",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "SQL query to execute"
                        }
                    },
                    "required": ["query"]
                }
            }
        ]
    })
    
    # Ejemplo: Servidor MCP para clima
    self.mcp_handler.add_mcp_server("weather", {
        "url": "https://weather-mcp.example.com",
        "api_key": "your_api_key",
        "tools": [
            {
                "name": "get_weather",
                "description": "Get current weather for a location",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "City name or coordinates"
                        }
                    },
                    "required": ["location"]
                }
            }
        ]
    })
```

### Paso 2: Implementar la Comunicaci√≥n con el Servidor

`call_mcp_tool` (en `mcp_handler.py`) ya viene implementado usando `httpx`:

- Busca qu√© servidor contiene el tool solicitado
- Env√≠a un `POST {url}/tools/<tool_name>` con `{"arguments": {...}}`
- Incluye autom√°ticamente `Authorization: Bearer <api_key>` si est√° configurado

Solo necesitas asegurarte de que tu servidor MCP siga ese contrato HTTP.

## üÜï Servidor MCP con OpenAI incluido

Este repositorio trae un servidor MCP listo para usar (`mcp_servers/openai_server.py`).  
Puedes correrlo **embebido dentro de la misma API** (ideal para Railway) o como servicio separado.

### Modo embebido (auto en Railway / producci√≥n)

1. **Variables en el servicio principal** (`.env` o panel de Railway):
   ```
   OPENAI_API_KEY=sk-...
   OPENAI_MCP_SERVER_KEY=un_token_seguro
   OPENAI_MCP_API_KEY=un_token_seguro         # mismo valor que arriba
   OPENAI_MCP_ROUTE_PREFIX=/mcp               # opcional
   EMBED_MCP_SERVER=true                      # viene true por defecto
   OPENAI_MCP_URL=http://127.0.0.1:8000/mcp   # opcional, se autoconfigura
   ```
   Si `OPENAI_MCP_URL` no est√° definido, el bot usar√° `http://127.0.0.1:<PORT>/mcp` autom√°ticamente.

2. Reinicia el servicio principal. El FastAPI incluye el router del MCP y expone:
   - `GET /mcp/health`
   - `POST /mcp/tools/openai_chat`

3. Usa la URL p√∫blica del mismo servicio (ej. `https://tuapp.up.railway.app/mcp`) si necesitas compartirla externamente.

### Modo servicio separado (opcional)

Si prefieres aislarlo:

1. Crea otro servicio con este repo y usa como comando de arranque:
   ```
   python -m mcp_servers.openai_server
   ```

2. Asigna las mismas variables (`OPENAI_API_KEY`, `OPENAI_MCP_SERVER_KEY`, `DATABASE_URL`, etc.) en ese servicio.

3. En el `.env` del bot apunta `OPENAI_MCP_URL` a la URL p√∫blica del nuevo servicio.

En ambos casos, el flujo es el mismo: el bot env√≠a la conversaci√≥n completa + contacto, el servidor MCP consulta PostgreSQL, llama a OpenAI y devuelve la respuesta final.

## üìã Servidores MCP Disponibles

Groq tiene integraciones oficiales con varios servidores MCP:

- **BrowserBase MCP** - Navegaci√≥n web
- **BrowserUse MCP** - Automatizaci√≥n de navegador
- **Exa MCP** - B√∫squeda sem√°ntica
- **Firecrawl MCP** - Web scraping
- **HuggingFace MCP** - Modelos de ML
- **Parallel MCP** - Procesamiento paralelo
- **Stripe MCP** - Pagos
- **Tavily MCP** - B√∫squeda web

## üéØ Ejemplo de Uso

Cuando el modelo detecta que necesita usar una herramienta:

1. **Usuario pregunta:** "¬øQu√© tiempo hace en Villarrica?"
2. **Modelo detecta:** Necesita usar `get_weather`
3. **Sistema llama:** La herramienta autom√°ticamente
4. **Resultado se incluye:** En la respuesta final

Todo esto ocurre **autom√°ticamente** - el modelo decide cu√°ndo usar las herramientas.

## ‚öôÔ∏è Configuraci√≥n

Por defecto, MCP est√° **deshabilitado** hasta que agregues servidores. Una vez que agregues servidores en `_initialize_mcp_servers()`, MCP se habilitar√° autom√°ticamente.

## üîç Debugging

Para ver si MCP est√° funcionando, revisa los logs:

```
INFO: Using 2 MCP tools for this request
INFO: Model requested 1 tool calls
INFO: Calling MCP tool 'get_weather' from server 'weather'
```

## üìö Recursos

- [Groq MCP Blog Post](https://groq.com/blog/introducing-remote-mcp-support-in-beta-on-groqcloud)
- [Groq MCP Server GitHub](https://github.com/groq/groq-mcp-server)
- [MCP Specification](https://modelcontextprotocol.io)

## ‚úÖ Estado de Implementaci√≥n

- ‚úÖ Estructura base de MCP handler
- ‚úÖ Integraci√≥n con Groq function calling
- ‚úÖ Soporte para m√∫ltiples servidores MCP
- ‚úÖ Manejo autom√°tico de tool calling
- ‚ö†Ô∏è Implementaci√≥n de comunicaci√≥n HTTP con servidores MCP (pendiente - necesitas completar seg√∫n tus servidores)

---

**Nota:** La estructura est√° lista. Solo necesitas implementar la comunicaci√≥n real con tus servidores MCP espec√≠ficos en el m√©todo `call_mcp_tool`.

