# üîå Integraci√≥n MCP (Model Context Protocol)

## ‚úÖ Estado Actual

El bot ahora tiene **compatibilidad completa con MCP servers** gracias a Groq, que soporta el protocolo compatible con OpenAI function calling.

## üéØ ¬øQu√© es MCP?

**Model Context Protocol (MCP)** es un protocolo desarrollado por Anthropic que permite que los modelos de IA se conecten con servicios externos y herramientas en tiempo real. Esto permite:

- Conectarse a bases de datos
- Interactuar con APIs externas
- Usar herramientas de navegaci√≥n web
- Integrar con servicios como GitHub, Stripe, etc.

## üöÄ C√≥mo Funciona con Groq

Groq tiene soporte nativo para **function calling** compatible con OpenAI, lo que significa que:

1. ‚úÖ El modelo puede decidir cu√°ndo usar herramientas
2. ‚úÖ Las herramientas se llaman autom√°ticamente cuando el modelo las necesita
3. ‚úÖ El resultado de la herramienta se incluye en la respuesta final

## üìÅ Archivos Creados

### `app/bot/mcp_handler.py`
Maneja las conexiones a servidores MCP y la ejecuci√≥n de herramientas.

**Caracter√≠sticas:**
- Gesti√≥n de m√∫ltiples servidores MCP
- Registro de herramientas disponibles
- Ejecuci√≥n de llamadas a herramientas
- Formato compatible con OpenAI function calling

### `app/bot/ai_handler.py` (actualizado)
Ahora incluye:
- Soporte para MCP handlers
- Detecci√≥n autom√°tica de herramientas disponibles
- Manejo de tool calling del modelo
- Respuestas con contexto de herramientas

### `mcp_servers/openai_server.py` (nuevo)
- Servidor FastAPI que expone el tool `openai_chat`
- Usa el SDK oficial de OpenAI para generar la respuesta final
- Incluye autenticaci√≥n por token y configuraci√≥n v√≠a variables de entorno

## üîß C√≥mo Agregar Servidores MCP

### Paso 1: Configurar un Servidor MCP

Edita `app/bot/ai_handler.py` y agrega tu servidor en el m√©todo `_initialize_mcp_servers()`:

```python
def _initialize_mcp_servers(self):
    """Initialize MCP servers from configuration"""
    
    # Ejemplo: Servidor MCP para base de datos
    self.mcp_handler.add_mcp_server("database", {
        "url": "https://mcp-server.example.com",
        "api_key": None,
        "tools": [
            {
                "name": "query_database",
                "description": "Query the database for customer information",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "SQL query to execute"
                        }
                    },
                    "required": ["query"]
                }
            }
        ]
    })
    
    # Ejemplo: Servidor MCP para clima
    self.mcp_handler.add_mcp_server("weather", {
        "url": "https://weather-mcp.example.com",
        "api_key": "your_api_key",
        "tools": [
            {
                "name": "get_weather",
                "description": "Get current weather for a location",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "City name or coordinates"
                        }
                    },
                    "required": ["location"]
                }
            }
        ]
    })
```

### Paso 2: Implementar la Comunicaci√≥n con el Servidor

`call_mcp_tool` (en `mcp_handler.py`) ya viene implementado usando `httpx`:

- Busca qu√© servidor contiene el tool solicitado
- Env√≠a un `POST {url}/tools/<tool_name>` con `{"arguments": {...}}`
- Incluye autom√°ticamente `Authorization: Bearer <api_key>` si est√° configurado

Solo necesitas asegurarte de que tu servidor MCP siga ese contrato HTTP.

## üÜï Servidor MCP con OpenAI incluido

Este repositorio ahora trae un servidor MCP listo para usar (`mcp_servers/openai_server.py`).  
Te permite responder TODO el chat con OpenAI, manteniendo al bot como un simple cliente MCP.

1. **Configura el bot (`.env`)**
   ```
   OPENAI_MCP_URL=http://localhost:9000
   OPENAI_MCP_API_KEY=tu_token_para_el_bot
   OPENAI_MCP_TOOL_NAME=openai_chat
   ```

2. **Configura el servidor MCP (variables en la terminal donde lo correr√°s)**
   ```
   OPENAI_API_KEY=sk-...
   OPENAI_MCP_SERVER_KEY=tu_token_para_el_bot      # Debe coincidir
   OPENAI_MCP_MODEL=gpt-4o-mini                    # Opcional
   OPENAI_MCP_PORT=9000                            # Opcional
   ```

3. **Ejecuta el servidor**
   ```bash
   python -m mcp_servers.openai_server
   ```
   Esto abrir√° `http://0.0.0.0:9000/tools/openai_chat`.

4. **Inicia el bot normalmente**
   `AIHandler` detectar√° el tool y enviar√° la conversaci√≥n completa al servidor MCP.  
   Si `openai_chat` responde con √©xito, el bot NO usar√° Groq para esa respuesta (queda como fallback autom√°tico).

## üìã Servidores MCP Disponibles

Groq tiene integraciones oficiales con varios servidores MCP:

- **BrowserBase MCP** - Navegaci√≥n web
- **BrowserUse MCP** - Automatizaci√≥n de navegador
- **Exa MCP** - B√∫squeda sem√°ntica
- **Firecrawl MCP** - Web scraping
- **HuggingFace MCP** - Modelos de ML
- **Parallel MCP** - Procesamiento paralelo
- **Stripe MCP** - Pagos
- **Tavily MCP** - B√∫squeda web

## üéØ Ejemplo de Uso

Cuando el modelo detecta que necesita usar una herramienta:

1. **Usuario pregunta:** "¬øQu√© tiempo hace en Villarrica?"
2. **Modelo detecta:** Necesita usar `get_weather`
3. **Sistema llama:** La herramienta autom√°ticamente
4. **Resultado se incluye:** En la respuesta final

Todo esto ocurre **autom√°ticamente** - el modelo decide cu√°ndo usar las herramientas.

## ‚öôÔ∏è Configuraci√≥n

Por defecto, MCP est√° **deshabilitado** hasta que agregues servidores. Una vez que agregues servidores en `_initialize_mcp_servers()`, MCP se habilitar√° autom√°ticamente.

## üîç Debugging

Para ver si MCP est√° funcionando, revisa los logs:

```
INFO: Using 2 MCP tools for this request
INFO: Model requested 1 tool calls
INFO: Calling MCP tool 'get_weather' from server 'weather'
```

## üìö Recursos

- [Groq MCP Blog Post](https://groq.com/blog/introducing-remote-mcp-support-in-beta-on-groqcloud)
- [Groq MCP Server GitHub](https://github.com/groq/groq-mcp-server)
- [MCP Specification](https://modelcontextprotocol.io)

## ‚úÖ Estado de Implementaci√≥n

- ‚úÖ Estructura base de MCP handler
- ‚úÖ Integraci√≥n con Groq function calling
- ‚úÖ Soporte para m√∫ltiples servidores MCP
- ‚úÖ Manejo autom√°tico de tool calling
- ‚ö†Ô∏è Implementaci√≥n de comunicaci√≥n HTTP con servidores MCP (pendiente - necesitas completar seg√∫n tus servidores)

---

**Nota:** La estructura est√° lista. Solo necesitas implementar la comunicaci√≥n real con tus servidores MCP espec√≠ficos en el m√©todo `call_mcp_tool`.

